<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
<link rel="stylesheet" href="/forest/katex/katex.min.css">

  
<link rel="stylesheet" href="/forest/style.css">

  
<script src="/forest/katex/katex.min.js"></script>

  
<script src="/forest/jquery/jquery-3.6.4.min.js"></script>

<meta name="generator" content="Hexo 6.3.0"></head>
<body>
<!-- header -->

<!-- content -->
<!--
  Partial for a single tree.

  spliced: Whether the tree is being spliced. If true,
    the title is not displayed, and the layout is
    somewhat more compact.
  expanded: Whether the tree should be expanded by default.
  content: The tree content, an html string.
  title: The title.
-->


<article class="tree">
  <details open >
    <summary><b>Convergence of functions</b></summary>
    <html><head></head><body><div class="btex-output"><p>There are many notions of convergence of functions in analysis. The most natural one is <b>pointwise convergence</b>, or more leniently <b>almost everywhere convergence</b>. These generally produces very wild functions, as the convergence rate at each point is completely unrelated. We may also require <b>uniform convergence</b>. This is the strictest kind of convergence. It also has an “almost everywhere” variant, where there is a measure zero set <span class="inline-math"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span style="margin-right: 0.0715em;" class="mord mathnormal">Z</span></span></span></span></span> outside of which the function converges uniformly.</p><p>There are other notions in between. In complex analysis we often encounter <b>uniform convergence on all compact sets</b>. This is the sequential version of the compact-open topology. In real analysis, a function may converge uniformly on a set whose complement can be made arbitrarily small (but non-zero). This is called <b>nearly uniform convergence</b>. Note that this makes sense because uniform convergence is a <i>global</i> concept. In contrast, “nearly everywhere convergence” is simply almost everywhere convergence, because pointwise convergence is completely local.</p><p>Finally, there is <b>convergence in measure</b>, which comes from the study of probability. It requires that for every <span class="inline-math"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span></span>, the measure of the set on which the functions differ by more than <span class="inline-math"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span></span> tends to zero.</p></div></body></html>
  </details>
</article>




<!-- footer -->
</body>
</html>
